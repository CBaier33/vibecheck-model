# vibecheck

create displays based off detected emotion from a conversation.

## step 1

### gather sample data for emotions

// using the ravdess dataset to create the basic model
https://zenodo.org/records/1188976#.X4sE0tDXKUl

### questions
- which emotions?

- how many

- how long are each?

## step 2
### develop machine learning model

https://github.com/MeidanGR/SpeechEmotionRecognition_Realtime/blob/main/3_realtime_ser.ipynb

### questions

- what model?

- what language?

## step 3
### frontend

- flutter?

- creating colors?

- accessing model?

## step 4
### service model to frontend

- home server?

- audio processing?

- encoding?

- concurrency? (what)
